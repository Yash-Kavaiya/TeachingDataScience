{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bandits = [0.2, 0, -0.2, -5]  # lower bandit number, higher chance of positive reward\n",
    "num_bandits = len(bandits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reward mechanism\n",
    "\n",
    "def pullBandit(bandit):\n",
    "    #Get a random number\n",
    "    result = np.random.randn(1)\n",
    "    if result > bandit:\n",
    "        return 1  # positive reward\n",
    "    else:\n",
    "        return -1 #negative reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04469142])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feed forward net\n",
    "weights = tf.Variable(tf.ones([num_bandits]))  # each weight corresponds to one bandit\n",
    "                                               # represnets how good it is to pull that arm and do that action\n",
    "chosen_action = tf.argmax(weights,0)     #action with highest weight\n",
    "\n",
    "# feed reward and chosen action to compute loss\n",
    "reward_holder = tf.placeholder(shape=[1], dtype=tf.float32)  # reward from selected action\n",
    "action_holder = tf.placeholder(shape=[1], dtype=tf.int32)  #index of chosen action\n",
    "responsible_weight = tf.slice(weights, action_holder, [1]) #find weight of chosen action from weights vector\n",
    "loss = -(tf.log(responsible_weight)*reward_holder)  # Log(policy)*A - compute policy gradient loss\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001) \n",
    "update = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward for the 4 bandits: [-1.  0.  0.  0.]\n",
      "[ 1.  1.  1.  1.]\n",
      "Running reward for the 4 bandits: [-1.  1.  5.  2.]\n",
      "[ 0.99900109  1.00100613  1.00599766  1.00199902]\n",
      "Running reward for the 4 bandits: [ -1.   0.  22.   2.]\n",
      "[ 0.9990021   1.00000715  1.02277887  1.00199902]\n",
      "Running reward for the 4 bandits: [ -2.  -3.  21.   3.]\n",
      "[ 0.9980011   0.99700415  1.02084303  1.00199902]\n",
      "Running reward for the 4 bandits: [ -3.   0.  31.   3.]\n",
      "[ 0.9980011   1.00001013  1.0306133   1.00299704]\n",
      "Running reward for the 4 bandits: [ -3.   1.  30.   9.]\n",
      "[ 0.99699908  1.00101018  1.02869022  1.0089643 ]\n",
      "Running reward for the 4 bandits: [ -3.   0.  33.   9.]\n",
      "[ 0.99699908  1.00001121  1.03356147  1.0089643 ]\n",
      "Running reward for the 4 bandits: [ -3.  -2.  37.   9.]\n",
      "[ 0.99699908  0.99801022  1.03551614  1.0089643 ]\n",
      "Running reward for the 4 bandits: [ -3.  -2.  43.  11.]\n",
      "[ 0.9970001   0.99801022  1.04323339  1.01094556]\n",
      "Running reward for the 4 bandits: [ -2.  -2.  48.  11.]\n",
      "[ 0.99800313  0.99801022  1.04612696  1.01094556]\n",
      "Running reward for the 4 bandits: [ -2.  -2.  57.  12.]\n",
      "[ 0.99800414  0.99801022  1.05471516  1.01193476]\n",
      "Running reward for the 4 bandits: [ -4.  -1.  68.  12.]\n",
      "[ 0.9959991   0.99901223  1.06511307  1.01193476]\n",
      "Running reward for the 4 bandits: [ -5.  -1.  74.  15.]\n",
      "[ 0.99499506  0.99901223  1.07075059  1.01489663]\n",
      "Running reward for the 4 bandits: [ -4.  -3.  87.  15.]\n",
      "[ 0.99600011  0.99700922  1.08284199  1.01489663]\n",
      "Running reward for the 4 bandits: [ -4.   0.  97.  16.]\n",
      "[ 0.99600011  1.00001526  1.09205604  1.0158819 ]\n",
      "Running reward for the 4 bandits: [  -4.    2.  108.   17.]\n",
      "[ 0.99600112  1.00201416  1.10391283  1.01686621]\n",
      "Running reward for the 4 bandits: [  -4.    1.  104.   18.]\n",
      "[ 0.99600112  1.00101614  1.10030138  1.01784956]\n",
      "Running reward for the 4 bandits: [  -3.   -1.  105.   20.]\n",
      "[ 0.99700516  0.99901813  1.09940803  1.01981366]\n",
      "Running reward for the 4 bandits: [  -5.   -1.  118.   21.]\n",
      "[ 0.9949981   0.99901915  1.11298466  1.02079427]\n",
      "Running reward for the 4 bandits: [  -4.   -1.  124.   22.]\n",
      "[ 0.99600315  0.99901915  1.11659002  1.02177393]\n",
      "the agent thinks most promising bandit is 3\n"
     ]
    }
   ],
   "source": [
    "#training the agent\n",
    "\n",
    "total_episodes = 1000\n",
    "total_reward = np.zeros(num_bandits) # scoreboard of bandits started at 0\n",
    "e = 0.1 #chance of taking a random action\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    i = 0\n",
    "    while i < total_episodes:\n",
    "        # choose random action or one with heighest weights with e-greedy prob\n",
    "        if np.random.rand(1) < e:\n",
    "            action = np.random.randint(num_bandits)\n",
    "        else:\n",
    "            action = sess.run(chosen_action)\n",
    "        \n",
    "        # implement action to get reward\n",
    "        reward = pullBandit(bandits[action]) #get reward from picking a bandit\n",
    "        \n",
    "        #update the network, pass in reward and selected action\n",
    "        _, resp, ww = sess.run([update, responsible_weight, weights], feed_dict={reward_holder:[reward],\n",
    "                                                                                action_holder:[action]})\n",
    "        \n",
    "        # update scores - add reward of that action to total scoreboard\n",
    "        total_reward[action] += reward\n",
    "        \n",
    "        if i%50==0:\n",
    "            print(\"Running reward for the \"+str(num_bandits)+\" bandits: \"+str(total_reward))\n",
    "            print(ww)\n",
    "        \n",
    "        i+=1\n",
    "print(\"the agent thinks most promising bandit is\",str(np.argmax(ww)+1))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t= np.ones([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(t,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.29588233,  0.15985818, -0.27136887,  0.20369762])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(4)*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
