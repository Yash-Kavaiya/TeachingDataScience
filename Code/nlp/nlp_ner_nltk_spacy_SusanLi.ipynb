{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_tree = ne_chunk(pos_tag(word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE European/JJ)\n",
      "  authorities/NNS\n",
      "  fined/VBD\n",
      "  (PERSON Google/NNP)\n",
      "  a/DT\n",
      "  record/NN\n",
      "  $/$\n",
      "  5.1/CD\n",
      "  billion/CD\n",
      "  on/IN\n",
      "  Wednesday/NNP\n",
      "  for/IN\n",
      "  abusing/VBG\n",
      "  its/PRP$\n",
      "  power/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  mobile/JJ\n",
      "  phone/NN\n",
      "  market/NN\n",
      "  and/CC\n",
      "  ordered/VBD\n",
      "  the/DT\n",
      "  company/NN\n",
      "  to/TO\n",
      "  alter/VB\n",
      "  its/PRP$\n",
      "  practices/NNS)\n"
     ]
    }
   ],
   "source": [
    "print(ne_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = 'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('European', 'JJ'),\n",
       " ('authorities', 'NNS'),\n",
       " ('fined', 'VBD'),\n",
       " ('Google', 'NNP'),\n",
       " ('a', 'DT'),\n",
       " ('record', 'NN'),\n",
       " ('$', '$'),\n",
       " ('5.1', 'CD'),\n",
       " ('billion', 'CD'),\n",
       " ('on', 'IN'),\n",
       " ('Wednesday', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('abusing', 'VBG'),\n",
       " ('its', 'PRP$'),\n",
       " ('power', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('mobile', 'JJ'),\n",
       " ('phone', 'NN'),\n",
       " ('market', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('ordered', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('company', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('alter', 'VB'),\n",
       " ('its', 'PRP$'),\n",
       " ('practices', 'NNS')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = preprocess(ex)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'NP: {<DT>?<JJ>*<NN>}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  European/JJ\n",
      "  authorities/NNS\n",
      "  fined/VBD\n",
      "  Google/NNP\n",
      "  (NP a/DT record/NN)\n",
      "  $/$\n",
      "  5.1/CD\n",
      "  billion/CD\n",
      "  on/IN\n",
      "  Wednesday/NNP\n",
      "  for/IN\n",
      "  abusing/VBG\n",
      "  its/PRP$\n",
      "  (NP power/NN)\n",
      "  in/IN\n",
      "  (NP the/DT mobile/JJ phone/NN)\n",
      "  (NP market/NN)\n",
      "  and/CC\n",
      "  ordered/VBD\n",
      "  (NP the/DT company/NN)\n",
      "  to/TO\n",
      "  alter/VB\n",
      "  its/PRP$\n",
      "  practices/NNS)\n"
     ]
    }
   ],
   "source": [
    "cp = nltk.RegexpParser(pattern)\n",
    "cs = cp.parse(sent)\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPChunker = nltk.RegexpParser(pattern) \n",
    "result = NPChunker.parse(sent)\n",
    "result.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('European', 'JJ', 'O'),\n",
      " ('authorities', 'NNS', 'O'),\n",
      " ('fined', 'VBD', 'O'),\n",
      " ('Google', 'NNP', 'O'),\n",
      " ('a', 'DT', 'B-NP'),\n",
      " ('record', 'NN', 'I-NP'),\n",
      " ('$', '$', 'O'),\n",
      " ('5.1', 'CD', 'O'),\n",
      " ('billion', 'CD', 'O'),\n",
      " ('on', 'IN', 'O'),\n",
      " ('Wednesday', 'NNP', 'O'),\n",
      " ('for', 'IN', 'O'),\n",
      " ('abusing', 'VBG', 'O'),\n",
      " ('its', 'PRP$', 'O'),\n",
      " ('power', 'NN', 'B-NP'),\n",
      " ('in', 'IN', 'O'),\n",
      " ('the', 'DT', 'B-NP'),\n",
      " ('mobile', 'JJ', 'I-NP'),\n",
      " ('phone', 'NN', 'I-NP'),\n",
      " ('market', 'NN', 'B-NP'),\n",
      " ('and', 'CC', 'O'),\n",
      " ('ordered', 'VBD', 'O'),\n",
      " ('the', 'DT', 'B-NP'),\n",
      " ('company', 'NN', 'I-NP'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('alter', 'VB', 'O'),\n",
      " ('its', 'PRP$', 'O'),\n",
      " ('practices', 'NNS', 'O')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from pprint import pprint\n",
    "\n",
    "iob_tagged = tree2conlltags(cs)\n",
    "pprint(iob_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'displacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-86b5dfc9b16e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdisplacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'displacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices')\n",
    "pprint([(X.text, X.label_) for X in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint([(X, X.ent_iob_, X.ent_type_) for X in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_string(url):\n",
    "    res = requests.get(url)\n",
    "    html = res.text\n",
    "    soup = BeautifulSoup(html, 'html5lib')\n",
    "    for script in soup([\"script\", \"style\", 'aside']):\n",
    "        script.extract()\n",
    "    return \" \".join(re.split(r'[\\n\\t]+', soup.get_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_bb = url_to_string('https://www.nytimes.com/2018/08/13/us/politics/peter-strzok-fired-fbi.html?hp&action=click&pgtype=Homepage&clickSource=story-heading&module=first-column-region&region=top-news&WT.nav=top-news')\n",
    "article = nlp(ny_bb)\n",
    "len(article.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [x.label_ for x in article.ents]\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [x.text for x in article.ents]\n",
    "Counter(items).most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [x for x in article.sents]\n",
    "print(sentences[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(nlp(str(sentences[20])), jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(nlp(str(sentences[20])), style='dep', jupyter = True, options = {'distance': 120})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(x.orth_,x.pos_, x.lemma_) for x in [y \n",
    "                                      for y\n",
    "                                      in nlp(str(sentences[20])) \n",
    "                                      if not y.is_stop and y.pos_ != 'PUNCT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict([(str(x), x.label_) for x in nlp(str(sentences[20])).ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([(x, x.ent_iob_, x.ent_type_) for x in sentences[20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "displacy.render(article, jupyter=True, style='ent')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
