# -*- coding: utf-8 -*-
"""3. Semi-Supervised Learning GANs (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H_WbyzsBaT90ONDma-EzJjsGJAbFxZb7

##Semi-supervised learning GAN's

Semi-supervised learning is the challenging problem of training a classifier in a dataset that contains a small number of labeled examples and a much larger number of unlabeled examples.

The semi-supervised GAN, or SGAN, model is an extension of the GAN architecture that involves the simultaneous training of a supervised discriminator, unsupervised discriminator, and a generator model. The result is both a supervised classification model that generalizes well to unseen examples and a generator model that outputs plausible examples of images from the domain.


In this tutorial, you will discover how to develop a Semi-Supervised Generative Adversarial Network from scratch on the MNIST dataset.[link text](https://)

##Importing Libraries
"""

import tensorflow as tf
import numpy as np
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import math

"""### Load and Prepare Data"""

#Load MNIST data
(train_x, train_y),(test_x, test_y) = tf.keras.datasets.mnist.load_data()
#Shape
train_x.shape

#Reshape images to be 3D
train_x = np.reshape(train_x, (-1,28,28,1))
test_x = np.reshape(test_x, (-1,28,28,1))

train_x.shape, test_x.shape

#Normalize Data
train_x = train_x/127.5 - 1
test_x = test_x/127.5 - 1

"""#Split Training Data between Supervised and Unsupervised Examples

15% of the data will be used in Supervised learning while rest of it will be used for UnSupervised Learning.
"""

supervised_data_percent = 0.015
unsupervised_data_percent = 1 - supervised_data_percent

train_x_sup, train_x_unsup, train_y_sup, train_y_unsup = train_test_split(train_x, train_y, 
                                                                          train_size=supervised_data_percent,
                                                                          test_size=unsupervised_data_percent)

train_x_sup.shape

"""Following function will do 2 things:

1. Convert MNIST labels to One-hot encoding
2. Append a column at the end with zeros to indicate Fake Image
"""

def prepare_labels(y):
    
    extended_labels = tf.keras.utils.to_categorical(y, 10)
    extended_labels = np.concatenate([extended_labels, np.zeros((extended_labels.shape[0],1))], axis=1)
    
    return extended_labels

"""### Build Generator

Generator will take 100 random numbers as input and will produce an image of shape (28,28,1). Image data values will be between -1 to 1.
"""

def generator(input_x, training, reuse=False):
    
    with tf.variable_scope('Generator', reuse=reuse) as scope:
        
        #Layer 0
        x = tf.keras.layers.Reshape((1,1,100,))(input_x)
        
        #Layer 1
        x = tf.keras.layers.Conv2DTranspose(100, kernel_size=(2,2), strides=1, padding='valid')(x)
        x = tf.layers.batch_normalization(x, training=training)
        x = tf.keras.activations.relu(x)
        
        #Layer 2
        x = tf.keras.layers.Conv2DTranspose(64, kernel_size=(3,3), strides=2, padding='valid')(x)
        x = tf.layers.batch_normalization(x, training=training)
        x = tf.keras.activations.relu(x)
        
        #Layer 3
        x = tf.keras.layers.Conv2DTranspose(32, kernel_size=(4,4), strides=2, padding='valid')(x)
        x = tf.layers.batch_normalization(x, training=training)
        x = tf.keras.activations.relu(x)
        
        #Layer 4
        x = tf.keras.layers.Conv2DTranspose(1, kernel_size=(6,6), strides=2, padding='valid')(x)
        x = tf.keras.activations.tanh(x)
        
        return x

"""### How to Implement the Semi-Supervised Discriminator Model

There are a number of ways that we can implement the discriminator model for the semi-supervised GAN.

In this section, we will review three candidate approaches.

#Traditional Discriminator Model
Consider a discriminator model for the standard GAN model.

It must take an image as input and predict whether it is real or fake. More specifically, it predicts the likelihood of the input image being real. The output layer uses a sigmoid activation function to predict a probability value in [0,1] and the model is typically optimized using a binary cross entropy loss function.

![picture](https://drive.google.com/uc?id=1me8S5Ud6Ryo9qem7ilDhmWPY_UiPwqfp)

#Separate Discriminator Models With Shared Weights

Starting with the standard GAN discriminator model, we can update it to create two models that share feature extraction weights.

Specifically, we can define one classifier model that predicts whether an input image is real or fake, and a second classifier model that predicts the class of a given model.

#Binary Classifier Model:
*Predicts whether the image is real or fake, sigmoid activation function in the output layer, and optimized using the binary cross entropy loss function.*
#Multi-Class Classifier Model: 
*Predicts the class of the image, softmax activation function in the output layer, and optimized using the categorical cross entropy loss function.*



Both models have different output layers but share all feature extraction layers. This means that updates to one of the classifier models will impact both models.

![picture](https://drive.google.com/uc?id=1_cg8BM63S71CQ8HQou-0B8mfC-h-MCfQ)

![picture](https://drive.google.com/uc?id=1g48J6m_CML7axiINxTpb4cEsaLkkBIxG)

##Single Discriminator Model With Multiple Outputs

Another approach to implementing the semi-supervised discriminator model is to have a single model with multiple output layers.

Specifically, this is a single model with one output layer for the unsupervised task and one output layer for the supervised task.

This is like having separate models for the supervised and unsupervised tasks in that they both share the same feature extraction layers, except that in this case, each input image always has two output predictions, specifically a real/fake prediction and a supervised class prediction.

A problem with this approach is that when the model is updated unlabeled and generated images, there is no supervised class label. In that case, these images must have an output label of “unknown” or “fake” from the supervised output. This means that an additional class label is required for the supervised output layer.

The example below implements the multi-output single model approach for the discriminator model in the semi-supervised GAN architecture with the help of Logits.
"""

def discriminator(input_d, p_drop, reuse=True, training = True):
    
    with tf.variable_scope('Discriminator', reuse=reuse) as scope:
        
        #Layer 1
        x = tf.keras.layers.Conv2D(32, kernel_size=(5,5), strides=2, padding='same')(input_d)
        x = tf.keras.layers.Dropout(p_drop)(x)
        x = tf.keras.activations.relu(x, alpha=0.2)
        
        #Layer 2
        x = tf.keras.layers.Conv2D(64, kernel_size=(3,3), strides=2, padding='same')(x)
        x = tf.layers.batch_normalization(x, training=training)
        x = tf.keras.activations.relu(x, alpha=0.2)
        
        #Layer 3
        x = tf.keras.layers.Conv2D(128, kernel_size=(2,2), strides=2, padding='same')(x)
        x = tf.layers.batch_normalization(x, training=training)
        x = tf.keras.activations.relu(x, alpha=0.2)
        x = tf.keras.layers.Dropout(p_drop)(x)
        
        #Layer 4
        x = tf.keras.layers.Conv2D(128, kernel_size=(2,2), strides=2, padding='same')(x)
        x = tf.keras.activations.relu(x, alpha=0.2)
        
        #Layer 5
        features = tf.keras.layers.Flatten()(x)
        logits = tf.keras.layers.Dense(11)(features)
        
        return features, logits

"""### Define Loss

We can see that the model is defined with two output layers and that the output layer for the supervised task is defined with n_classes + 1. in this case 11, making room for the additional “unknown” class label.

We can also see that the model is compiled to two loss functions, one for each output layer of the model.


Loss will be calculated for Discriminator and Generator. 

#### 1. Discriminator Loss

Following will be considered to calculate Loss:

Unsupervised:
1. Loss to predict Real Image is Real and Not fake.
2. Loss to predict Fake Image is Fake and Not Real.

Supervised:
1. Loss to predict MNIST label classification

#### 2. Generator Loss

Unsupervised Loss:
1. Loss to predict Fake Image as Real
2. Feature Mapping loss

![picture](https://drive.google.com/uc?id=1_oxX5wQ9lptgU8AJMwuDws6wgR9YqEI_)
"""

def model_loss(real_un_sup_ip, real_sup_ip, fake_ip, p_drop, training, y):
    
        
    #Get Discriminator output for Real Supervised Data
    rs_features, rs_logits = discriminator(real_sup_ip, p_drop, reuse=False, training=training)
    
    #Get Discriminator output for Real Un-Supervised Data
    ru_features, ru_logits = discriminator(real_un_sup_ip, p_drop, reuse=True, training=training)
    
    #Get Fake images from Generator
    fake_images = generator(fake_ip, training=training)
    
    #Get Dicriminator output for Fake images
    fake_features, fake_logits = discriminator(fake_images, p_drop, reuse=True, training=training)
    
    
    #Calculating Discriminator Loss
    
    #1. Let's calculate Unsupervised Loss for both Real and Fake data
    real_un_sup_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=ru_logits[:,-1], 
                                                                              labels=tf.zeros_like(ru_logits[:,-1])))
        
    
    fake_un_sup_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_logits[:,-1], 
                                                                              labels=tf.ones_like(fake_logits[:,-1])))
    
    #2. Supervised Loss
    real_sup_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=rs_logits, 
                                                                              labels=y))
    
    d_loss = real_un_sup_loss + fake_un_sup_loss + real_sup_loss
    
    
    #Calculating feature mapping loss for Generator
    tmp1 = tf.reduce_mean(ru_features, axis = 0)
    tmp2 = tf.reduce_mean(fake_features, axis = 0)
    feature_mapping_loss = tf.reduce_mean(tf.square(tmp1 - tmp2))
    
    #Fake vs Real loss
    fake_loss_2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_logits[:,-1], 
                                                                              labels=tf.zeros_like(fake_logits[:,-1])))
    
    #g_loss = feature_mapping_loss +  fake_loss_2
    g_loss = fake_loss_2
    
    rs_class_op = tf.nn.softmax(rs_logits)
    
    #Calculate Accuracy
    correct_prediction = tf.equal(tf.argmax(rs_class_op, axis=1), tf.argmax(y, axis=1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    
    return fake_images, d_loss, g_loss, accuracy

"""### Model Optimization

Training Discriminator and Generator models
"""

def model_optimization(d_loss, g_loss):
    
    # Get weights and biases to update. Get them separately for the discriminator and the generator
    discriminator_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES , scope='Discriminator')    
    generator_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Generator')
    
    #Minimize loss
    d_opt = tf.train.AdamOptimizer(name='d_optimizer').minimize(d_loss, var_list=discriminator_train_vars)
    
    g_opt = tf.train.AdamOptimizer(name='g_optimizer').minimize(g_loss, var_list=generator_train_vars)
    
    return d_opt, g_opt

"""### Training Module"""

def train(batch_size = 64, epochs = 1000):
    
    train_D_losses = []
    train_G_losses = []
    train_Accs  = []
    test_D_losses = []
    test_G_losses = []
    test_Accs = []
    noise_size = 100
    
    
    tf.reset_default_graph()
    
    #Declare Placeholders for input values
    real_sup_img = tf.placeholder(tf.float32, shape=(None,28,28,1))
    labels = tf.placeholder(tf.int64, shape=(None))
    
    real_unsup_img = tf.placeholder(tf.float32, shape=(None,28,28,1))
    
    noise_input = tf.placeholder(tf.float32, shape=(None, noise_size))
    
    dropout_rate = tf.placeholder(tf.float32)
    training = tf.placeholder(tf.bool)
    
    #Learning rate for Generator and Discriminator
    lr_g = tf.placeholder(tf.float32)
    lr_d = tf.placeholder(tf.float32)
    
    
    #Build the Graph
    fake_images, d_loss, g_loss, accuracy = model_loss(real_unsup_img, real_sup_img, noise_input, dropout_rate, 
                                                       training, labels)    
    d_opt, g_opt = model_optimization(d_loss, g_loss)
    
    
    #Execute Graph
    with tf.Session() as sess:
        
        sess.run(tf.global_variables_initializer())
        
        for i in range(epochs):
            
            #85% real images will be unsupervised
            unsup_indexes = np.random.randint(0, train_x_unsup.shape[0], size=int(0.9*batch_size))
            #15% of images will be supervised
            sup_indexes = np.random.randint(0, train_x_sup.shape[0], size=int(0.1*batch_size))
            
            
            train_feed_dict = {real_sup_img: train_x_sup[sup_indexes], 
                         labels: prepare_labels(train_y_sup[sup_indexes]), 
                         real_unsup_img: train_x_unsup[unsup_indexes], 
                         noise_input: np.random.uniform(-1.0, 1.0, size = (batch_size, 100)), 
                         dropout_rate: 0.5,
                         training: True,
                         lr_g: 1e-5, 
                         lr_d: 1e-5}
            
            _,_, dloss, gloss, acc = sess.run([d_opt, g_opt, d_loss, g_loss, accuracy], feed_dict=train_feed_dict)
            
            
            #Calculate Loss and Accuracy for Test Data
            if i % 200 == 0:
                
                print(i, '. Training Acc', acc, end='\t')
                train_Accs.append(acc)
                
                test_feed_dict = {real_sup_img: test_x, 
                         labels: prepare_labels(test_y), 
                         real_unsup_img: test_x, 
                         noise_input: np.random.uniform(-1.0, 1.0, size = (batch_size, 100)), 
                         dropout_rate: 0,
                         training: False}
                
                t_dloss, t_gloss, t_acc, fakeImgs = sess.run([d_loss, g_loss, accuracy, fake_images], 
                                                             feed_dict=test_feed_dict)
                
                test_Accs.append(t_acc)
                
                print('Test Acc', t_acc)
    return train_Accs, test_Accs

accs, val_accs = train(batch_size=32,epochs=20000)

def plot_images(fake_images):
    
    plt.figure(figsize=(2.2, 2.2))
    num_images = 16
    
    image_size = 28
    rows = 4
    
    for i in range(num_images):
        plt.subplot(rows, rows, i + 1)
        image = np.reshape(fake_images[i], [image_size, image_size])
        image = (image + 1)/2
        plt.imshow(image, cmap='gray')
        plt.axis('off')
    plt.show()

