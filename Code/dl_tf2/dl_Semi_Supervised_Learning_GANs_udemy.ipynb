{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Semi-Supervised Learning GANs (1).ipynb",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ2yGt2CBHG1"
      },
      "source": [
        "##Semi-supervised learning GAN's\n",
        "\n",
        "Semi-supervised learning is the challenging problem of training a classifier in a dataset that contains a small number of labeled examples and a much larger number of unlabeled examples.\n",
        "\n",
        "The semi-supervised GAN, or SGAN, model is an extension of the GAN architecture that involves the simultaneous training of a supervised discriminator, unsupervised discriminator, and a generator model. The result is both a supervised classification model that generalizes well to unseen examples and a generator model that outputs plausible examples of images from the domain.\n",
        "\n",
        "\n",
        "In this tutorial, you will discover how to develop a Semi-Supervised Generative Adversarial Network from scratch on the MNIST dataset.[link text](https://)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdxcGNiXQLNV"
      },
      "source": [
        "##Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FP7H8zgtuYQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBw2Mp8JtuYW"
      },
      "source": [
        "### Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSfvChhstuYX",
        "outputId": "8e08ffe2-587c-425d-8626-e6f0a6dfbe24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#Load MNIST data\n",
        "(train_x, train_y),(test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
        "#Shape\n",
        "train_x.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tgKko1otuYd"
      },
      "source": [
        "#Reshape images to be 3D\n",
        "train_x = np.reshape(train_x, (-1,28,28,1))\n",
        "test_x = np.reshape(test_x, (-1,28,28,1))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TMfEZv7tuYg",
        "outputId": "f6705146-533c-43af-ddce-c46d4bc7ef73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_x.shape, test_x.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (10000, 28, 28, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bwO_LM0tuYk"
      },
      "source": [
        "#Normalize Data\n",
        "train_x = train_x/127.5 - 1\n",
        "test_x = test_x/127.5 - 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9zlzXEituYo"
      },
      "source": [
        "#Split Training Data between Supervised and Unsupervised Examples\n",
        "\n",
        "15% of the data will be used in Supervised learning while rest of it will be used for UnSupervised Learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU9mN_9btuYp"
      },
      "source": [
        "supervised_data_percent = 0.015\n",
        "unsupervised_data_percent = 1 - supervised_data_percent"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtaNoqr4tuYs"
      },
      "source": [
        "train_x_sup, train_x_unsup, train_y_sup, train_y_unsup = train_test_split(train_x, train_y, \n",
        "                                                                          train_size=supervised_data_percent,\n",
        "                                                                          test_size=unsupervised_data_percent)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axIoHDsftuYv",
        "outputId": "b7d3fd93-d9b5-49c1-85ca-c33b65944ad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_x_sup.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(900, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFBiWddYtuYy"
      },
      "source": [
        "Following function will do 2 things:\n",
        "\n",
        "1. Convert MNIST labels to One-hot encoding\n",
        "2. Append a column at the end with zeros to indicate Fake Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g64eSPJRtuYz"
      },
      "source": [
        "def prepare_labels(y):\n",
        "    \n",
        "    extended_labels = tf.keras.utils.to_categorical(y, 10)\n",
        "    extended_labels = np.concatenate([extended_labels, np.zeros((extended_labels.shape[0],1))], axis=1)\n",
        "    \n",
        "    return extended_labels"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIfZbflZtuY1"
      },
      "source": [
        "### Build Generator\n",
        "\n",
        "Generator will take 100 random numbers as input and will produce an image of shape (28,28,1). Image data values will be between -1 to 1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms66ffRMtuY2"
      },
      "source": [
        "def generator(input_x, training, reuse=False):\n",
        "    \n",
        "    with tf.variable_scope('Generator', reuse=reuse) as scope:\n",
        "        \n",
        "        #Layer 0\n",
        "        x = tf.keras.layers.Reshape((1,1,100,))(input_x)\n",
        "        \n",
        "        #Layer 1\n",
        "        x = tf.keras.layers.Conv2DTranspose(100, kernel_size=(2,2), strides=1, padding='valid')(x)\n",
        "        x = tf.layers.batch_normalization(x, training=training)\n",
        "        x = tf.keras.activations.relu(x)\n",
        "        \n",
        "        #Layer 2\n",
        "        x = tf.keras.layers.Conv2DTranspose(64, kernel_size=(3,3), strides=2, padding='valid')(x)\n",
        "        x = tf.layers.batch_normalization(x, training=training)\n",
        "        x = tf.keras.activations.relu(x)\n",
        "        \n",
        "        #Layer 3\n",
        "        x = tf.keras.layers.Conv2DTranspose(32, kernel_size=(4,4), strides=2, padding='valid')(x)\n",
        "        x = tf.layers.batch_normalization(x, training=training)\n",
        "        x = tf.keras.activations.relu(x)\n",
        "        \n",
        "        #Layer 4\n",
        "        x = tf.keras.layers.Conv2DTranspose(1, kernel_size=(6,6), strides=2, padding='valid')(x)\n",
        "        x = tf.keras.activations.tanh(x)\n",
        "        \n",
        "        return x       "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdMOnym2tuY4"
      },
      "source": [
        "### How to Implement the Semi-Supervised Discriminator Model\n",
        "\n",
        "There are a number of ways that we can implement the discriminator model for the semi-supervised GAN.\n",
        "\n",
        "In this section, we will review three candidate approaches.\n",
        "\n",
        "#Traditional Discriminator Model\n",
        "Consider a discriminator model for the standard GAN model.\n",
        "\n",
        "It must take an image as input and predict whether it is real or fake. More specifically, it predicts the likelihood of the input image being real. The output layer uses a sigmoid activation function to predict a probability value in [0,1] and the model is typically optimized using a binary cross entropy loss function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJKTNpb6tLIs"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1me8S5Ud6Ryo9qem7ilDhmWPY_UiPwqfp) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7amVHH8iuJVX"
      },
      "source": [
        "#Separate Discriminator Models With Shared Weights\n",
        "\n",
        "Starting with the standard GAN discriminator model, we can update it to create two models that share feature extraction weights.\n",
        "\n",
        "Specifically, we can define one classifier model that predicts whether an input image is real or fake, and a second classifier model that predicts the class of a given model.\n",
        "\n",
        "#Binary Classifier Model:\n",
        "*Predicts whether the image is real or fake, sigmoid activation function in the output layer, and optimized using the binary cross entropy loss function.*\n",
        "#Multi-Class Classifier Model: \n",
        "*Predicts the class of the image, softmax activation function in the output layer, and optimized using the categorical cross entropy loss function.*\n",
        "\n",
        "\n",
        "\n",
        "Both models have different output layers but share all feature extraction layers. This means that updates to one of the classifier models will impact both models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSyHRsEJvHf0"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1_cg8BM63S71CQ8HQou-0B8mfC-h-MCfQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lq1e8vDvvIH"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1g48J6m_CML7axiINxTpb4cEsaLkkBIxG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG8C6pzRx3fI"
      },
      "source": [
        "##Single Discriminator Model With Multiple Outputs\n",
        "\n",
        "Another approach to implementing the semi-supervised discriminator model is to have a single model with multiple output layers.\n",
        "\n",
        "Specifically, this is a single model with one output layer for the unsupervised task and one output layer for the supervised task.\n",
        "\n",
        "This is like having separate models for the supervised and unsupervised tasks in that they both share the same feature extraction layers, except that in this case, each input image always has two output predictions, specifically a real/fake prediction and a supervised class prediction.\n",
        "\n",
        "A problem with this approach is that when the model is updated unlabeled and generated images, there is no supervised class label. In that case, these images must have an output label of “unknown” or “fake” from the supervised output. This means that an additional class label is required for the supervised output layer.\n",
        "\n",
        "The example below implements the multi-output single model approach for the discriminator model in the semi-supervised GAN architecture with the help of Logits.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6r_W6QKtuY5"
      },
      "source": [
        "def discriminator(input_d, p_drop, reuse=True, training = True):\n",
        "    \n",
        "    with tf.variable_scope('Discriminator', reuse=reuse) as scope:\n",
        "        \n",
        "        #Layer 1\n",
        "        x = tf.keras.layers.Conv2D(32, kernel_size=(5,5), strides=2, padding='same')(input_d)\n",
        "        x = tf.keras.layers.Dropout(p_drop)(x)\n",
        "        x = tf.keras.activations.relu(x, alpha=0.2)\n",
        "        \n",
        "        #Layer 2\n",
        "        x = tf.keras.layers.Conv2D(64, kernel_size=(3,3), strides=2, padding='same')(x)\n",
        "        x = tf.layers.batch_normalization(x, training=training)\n",
        "        x = tf.keras.activations.relu(x, alpha=0.2)\n",
        "        \n",
        "        #Layer 3\n",
        "        x = tf.keras.layers.Conv2D(128, kernel_size=(2,2), strides=2, padding='same')(x)\n",
        "        x = tf.layers.batch_normalization(x, training=training)\n",
        "        x = tf.keras.activations.relu(x, alpha=0.2)\n",
        "        x = tf.keras.layers.Dropout(p_drop)(x)\n",
        "        \n",
        "        #Layer 4\n",
        "        x = tf.keras.layers.Conv2D(128, kernel_size=(2,2), strides=2, padding='same')(x)\n",
        "        x = tf.keras.activations.relu(x, alpha=0.2)\n",
        "        \n",
        "        #Layer 5\n",
        "        features = tf.keras.layers.Flatten()(x)\n",
        "        logits = tf.keras.layers.Dense(11)(features)\n",
        "        \n",
        "        return features, logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyfWHDq-tuY7"
      },
      "source": [
        "### Define Loss\n",
        "\n",
        "We can see that the model is defined with two output layers and that the output layer for the supervised task is defined with n_classes + 1. in this case 11, making room for the additional “unknown” class label.\n",
        "\n",
        "We can also see that the model is compiled to two loss functions, one for each output layer of the model.\n",
        "\n",
        "\n",
        "Loss will be calculated for Discriminator and Generator. \n",
        "\n",
        "#### 1. Discriminator Loss\n",
        "\n",
        "Following will be considered to calculate Loss:\n",
        "\n",
        "Unsupervised:\n",
        "1. Loss to predict Real Image is Real and Not fake.\n",
        "2. Loss to predict Fake Image is Fake and Not Real.\n",
        "\n",
        "Supervised:\n",
        "1. Loss to predict MNIST label classification\n",
        "\n",
        "#### 2. Generator Loss\n",
        "\n",
        "Unsupervised Loss:\n",
        "1. Loss to predict Fake Image as Real\n",
        "2. Feature Mapping loss "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2hAzLfW7WbA"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1_oxX5wQ9lptgU8AJMwuDws6wgR9YqEI_)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGHXmCoUtuY8"
      },
      "source": [
        "def model_loss(real_un_sup_ip, real_sup_ip, fake_ip, p_drop, training, y):\n",
        "    \n",
        "        \n",
        "    #Get Discriminator output for Real Supervised Data\n",
        "    rs_features, rs_logits = discriminator(real_sup_ip, p_drop, reuse=False, training=training)\n",
        "    \n",
        "    #Get Discriminator output for Real Un-Supervised Data\n",
        "    ru_features, ru_logits = discriminator(real_un_sup_ip, p_drop, reuse=True, training=training)\n",
        "    \n",
        "    #Get Fake images from Generator\n",
        "    fake_images = generator(fake_ip, training=training)\n",
        "    \n",
        "    #Get Dicriminator output for Fake images\n",
        "    fake_features, fake_logits = discriminator(fake_images, p_drop, reuse=True, training=training)\n",
        "    \n",
        "    \n",
        "    #Calculating Discriminator Loss\n",
        "    \n",
        "    #1. Let's calculate Unsupervised Loss for both Real and Fake data\n",
        "    real_un_sup_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=ru_logits[:,-1], \n",
        "                                                                              labels=tf.zeros_like(ru_logits[:,-1])))\n",
        "        \n",
        "    \n",
        "    fake_un_sup_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_logits[:,-1], \n",
        "                                                                              labels=tf.ones_like(fake_logits[:,-1])))\n",
        "    \n",
        "    #2. Supervised Loss\n",
        "    real_sup_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=rs_logits, \n",
        "                                                                              labels=y))\n",
        "    \n",
        "    d_loss = real_un_sup_loss + fake_un_sup_loss + real_sup_loss\n",
        "    \n",
        "    \n",
        "    #Calculating feature mapping loss for Generator\n",
        "    tmp1 = tf.reduce_mean(ru_features, axis = 0)\n",
        "    tmp2 = tf.reduce_mean(fake_features, axis = 0)\n",
        "    feature_mapping_loss = tf.reduce_mean(tf.square(tmp1 - tmp2))\n",
        "    \n",
        "    #Fake vs Real loss\n",
        "    fake_loss_2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_logits[:,-1], \n",
        "                                                                              labels=tf.zeros_like(fake_logits[:,-1])))\n",
        "    \n",
        "    #g_loss = feature_mapping_loss +  fake_loss_2\n",
        "    g_loss = fake_loss_2\n",
        "    \n",
        "    rs_class_op = tf.nn.softmax(rs_logits)\n",
        "    \n",
        "    #Calculate Accuracy\n",
        "    correct_prediction = tf.equal(tf.argmax(rs_class_op, axis=1), tf.argmax(y, axis=1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    \n",
        "    return fake_images, d_loss, g_loss, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "373EM-j9tuZA"
      },
      "source": [
        "### Model Optimization\n",
        "\n",
        "Training Discriminator and Generator models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lDFl_5ttuZB"
      },
      "source": [
        "def model_optimization(d_loss, g_loss):\n",
        "    \n",
        "    # Get weights and biases to update. Get them separately for the discriminator and the generator\n",
        "    discriminator_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES , scope='Discriminator')    \n",
        "    generator_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Generator')\n",
        "    \n",
        "    #Minimize loss\n",
        "    d_opt = tf.train.AdamOptimizer(name='d_optimizer').minimize(d_loss, var_list=discriminator_train_vars)\n",
        "    \n",
        "    g_opt = tf.train.AdamOptimizer(name='g_optimizer').minimize(g_loss, var_list=generator_train_vars)\n",
        "    \n",
        "    return d_opt, g_opt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrRwdH02tuZE"
      },
      "source": [
        "### Training Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EOS77H4tuZF"
      },
      "source": [
        "def train(batch_size = 64, epochs = 1000):\n",
        "    \n",
        "    train_D_losses = []\n",
        "    train_G_losses = []\n",
        "    train_Accs  = []\n",
        "    test_D_losses = []\n",
        "    test_G_losses = []\n",
        "    test_Accs = []\n",
        "    noise_size = 100\n",
        "    \n",
        "    \n",
        "    tf.reset_default_graph()\n",
        "    \n",
        "    #Declare Placeholders for input values\n",
        "    real_sup_img = tf.placeholder(tf.float32, shape=(None,28,28,1))\n",
        "    labels = tf.placeholder(tf.int64, shape=(None))\n",
        "    \n",
        "    real_unsup_img = tf.placeholder(tf.float32, shape=(None,28,28,1))\n",
        "    \n",
        "    noise_input = tf.placeholder(tf.float32, shape=(None, noise_size))\n",
        "    \n",
        "    dropout_rate = tf.placeholder(tf.float32)\n",
        "    training = tf.placeholder(tf.bool)\n",
        "    \n",
        "    #Learning rate for Generator and Discriminator\n",
        "    lr_g = tf.placeholder(tf.float32)\n",
        "    lr_d = tf.placeholder(tf.float32)\n",
        "    \n",
        "    \n",
        "    #Build the Graph\n",
        "    fake_images, d_loss, g_loss, accuracy = model_loss(real_unsup_img, real_sup_img, noise_input, dropout_rate, \n",
        "                                                       training, labels)    \n",
        "    d_opt, g_opt = model_optimization(d_loss, g_loss)\n",
        "    \n",
        "    \n",
        "    #Execute Graph\n",
        "    with tf.Session() as sess:\n",
        "        \n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        \n",
        "        for i in range(epochs):\n",
        "            \n",
        "            #85% real images will be unsupervised\n",
        "            unsup_indexes = np.random.randint(0, train_x_unsup.shape[0], size=int(0.9*batch_size))\n",
        "            #15% of images will be supervised\n",
        "            sup_indexes = np.random.randint(0, train_x_sup.shape[0], size=int(0.1*batch_size))\n",
        "            \n",
        "            \n",
        "            train_feed_dict = {real_sup_img: train_x_sup[sup_indexes], \n",
        "                         labels: prepare_labels(train_y_sup[sup_indexes]), \n",
        "                         real_unsup_img: train_x_unsup[unsup_indexes], \n",
        "                         noise_input: np.random.uniform(-1.0, 1.0, size = (batch_size, 100)), \n",
        "                         dropout_rate: 0.5,\n",
        "                         training: True,\n",
        "                         lr_g: 1e-5, \n",
        "                         lr_d: 1e-5}\n",
        "            \n",
        "            _,_, dloss, gloss, acc = sess.run([d_opt, g_opt, d_loss, g_loss, accuracy], feed_dict=train_feed_dict)\n",
        "            \n",
        "            \n",
        "            #Calculate Loss and Accuracy for Test Data\n",
        "            if i % 200 == 0:\n",
        "                \n",
        "                print(i, '. Training Acc', acc, end='\\t')\n",
        "                train_Accs.append(acc)\n",
        "                \n",
        "                test_feed_dict = {real_sup_img: test_x, \n",
        "                         labels: prepare_labels(test_y), \n",
        "                         real_unsup_img: test_x, \n",
        "                         noise_input: np.random.uniform(-1.0, 1.0, size = (batch_size, 100)), \n",
        "                         dropout_rate: 0,\n",
        "                         training: False}\n",
        "                \n",
        "                t_dloss, t_gloss, t_acc, fakeImgs = sess.run([d_loss, g_loss, accuracy, fake_images], \n",
        "                                                             feed_dict=test_feed_dict)\n",
        "                \n",
        "                test_Accs.append(t_acc)\n",
        "                \n",
        "                print('Test Acc', t_acc)\n",
        "    return train_Accs, test_Accs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtgFn-fvtuZI",
        "outputId": "818967be-7fc4-43d0-f654-a5e35571511d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2043
        }
      },
      "source": [
        "accs, val_accs = train(batch_size=32,epochs=20000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0615 07:24:36.095830 139688085026688 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0615 07:24:36.177558 139688085026688 deprecation.py:323] From <ipython-input-11-c6f9ac8af9a2>:12: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
            "W0615 07:24:37.081521 139688085026688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0615 07:24:37.107459 139688085026688 deprecation.py:323] From <ipython-input-12-446ecc0d69b4>:29: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 . Training Acc 0.0\tTest Acc 0.1803\n",
            "200 . Training Acc 0.6666667\tTest Acc 0.7484\n",
            "400 . Training Acc 1.0\tTest Acc 0.884\n",
            "600 . Training Acc 1.0\tTest Acc 0.8979\n",
            "800 . Training Acc 1.0\tTest Acc 0.9089\n",
            "1000 . Training Acc 1.0\tTest Acc 0.8949\n",
            "1200 . Training Acc 1.0\tTest Acc 0.9139\n",
            "1400 . Training Acc 1.0\tTest Acc 0.899\n",
            "1600 . Training Acc 1.0\tTest Acc 0.89\n",
            "1800 . Training Acc 1.0\tTest Acc 0.9269\n",
            "2000 . Training Acc 1.0\tTest Acc 0.8995\n",
            "2200 . Training Acc 1.0\tTest Acc 0.8924\n",
            "2400 . Training Acc 1.0\tTest Acc 0.8982\n",
            "2600 . Training Acc 1.0\tTest Acc 0.9188\n",
            "2800 . Training Acc 1.0\tTest Acc 0.875\n",
            "3000 . Training Acc 1.0\tTest Acc 0.9098\n",
            "3200 . Training Acc 1.0\tTest Acc 0.9117\n",
            "3400 . Training Acc 1.0\tTest Acc 0.8926\n",
            "3600 . Training Acc 1.0\tTest Acc 0.87\n",
            "3800 . Training Acc 1.0\tTest Acc 0.9163\n",
            "4000 . Training Acc 1.0\tTest Acc 0.9147\n",
            "4200 . Training Acc 1.0\tTest Acc 0.9344\n",
            "4400 . Training Acc 1.0\tTest Acc 0.8877\n",
            "4600 . Training Acc 1.0\tTest Acc 0.8798\n",
            "4800 . Training Acc 1.0\tTest Acc 0.9061\n",
            "5000 . Training Acc 1.0\tTest Acc 0.9016\n",
            "5200 . Training Acc 1.0\tTest Acc 0.9297\n",
            "5400 . Training Acc 1.0\tTest Acc 0.9274\n",
            "5600 . Training Acc 1.0\tTest Acc 0.8901\n",
            "5800 . Training Acc 1.0\tTest Acc 0.924\n",
            "6000 . Training Acc 1.0\tTest Acc 0.9025\n",
            "6200 . Training Acc 1.0\tTest Acc 0.9149\n",
            "6400 . Training Acc 1.0\tTest Acc 0.9161\n",
            "6600 . Training Acc 1.0\tTest Acc 0.9219\n",
            "6800 . Training Acc 1.0\tTest Acc 0.9042\n",
            "7000 . Training Acc 1.0\tTest Acc 0.9211\n",
            "7200 . Training Acc 1.0\tTest Acc 0.9045\n",
            "7400 . Training Acc 1.0\tTest Acc 0.928\n",
            "7600 . Training Acc 1.0\tTest Acc 0.9112\n",
            "7800 . Training Acc 1.0\tTest Acc 0.9249\n",
            "8000 . Training Acc 1.0\tTest Acc 0.9256\n",
            "8200 . Training Acc 1.0\tTest Acc 0.9101\n",
            "8400 . Training Acc 1.0\tTest Acc 0.9124\n",
            "8600 . Training Acc 1.0\tTest Acc 0.9283\n",
            "8800 . Training Acc 1.0\tTest Acc 0.9012\n",
            "9000 . Training Acc 1.0\tTest Acc 0.92\n",
            "9200 . Training Acc 1.0\tTest Acc 0.9268\n",
            "9400 . Training Acc 1.0\tTest Acc 0.9302\n",
            "9600 . Training Acc 1.0\tTest Acc 0.9316\n",
            "9800 . Training Acc 1.0\tTest Acc 0.9263\n",
            "10000 . Training Acc 1.0\tTest Acc 0.9281\n",
            "10200 . Training Acc 1.0\tTest Acc 0.8898\n",
            "10400 . Training Acc 1.0\tTest Acc 0.8613\n",
            "10600 . Training Acc 1.0\tTest Acc 0.9053\n",
            "10800 . Training Acc 1.0\tTest Acc 0.9169\n",
            "11000 . Training Acc 1.0\tTest Acc 0.94\n",
            "11200 . Training Acc 1.0\tTest Acc 0.9359\n",
            "11400 . Training Acc 1.0\tTest Acc 0.9291\n",
            "11600 . Training Acc 1.0\tTest Acc 0.8948\n",
            "11800 . Training Acc 1.0\tTest Acc 0.9345\n",
            "12000 . Training Acc 1.0\tTest Acc 0.9398\n",
            "12200 . Training Acc 1.0\tTest Acc 0.9422\n",
            "12400 . Training Acc 1.0\tTest Acc 0.9421\n",
            "12600 . Training Acc 1.0\tTest Acc 0.9427\n",
            "12800 . Training Acc 1.0\tTest Acc 0.9425\n",
            "13000 . Training Acc 1.0\tTest Acc 0.9428\n",
            "13200 . Training Acc 1.0\tTest Acc 0.9423\n",
            "13400 . Training Acc 1.0\tTest Acc 0.9425\n",
            "13600 . Training Acc 1.0\tTest Acc 0.9427\n",
            "13800 . Training Acc 1.0\tTest Acc 0.9427\n",
            "14000 . Training Acc 1.0\tTest Acc 0.943\n",
            "14200 . Training Acc 1.0\tTest Acc 0.9432\n",
            "14400 . Training Acc 1.0\tTest Acc 0.943\n",
            "14600 . Training Acc 1.0\tTest Acc 0.9431\n",
            "14800 . Training Acc 1.0\tTest Acc 0.9431\n",
            "15000 . Training Acc 1.0\tTest Acc 0.9432\n",
            "15200 . Training Acc 1.0\tTest Acc 0.9432\n",
            "15400 . Training Acc 1.0\tTest Acc 0.9425\n",
            "15600 . Training Acc 1.0\tTest Acc 0.9429\n",
            "15800 . Training Acc 1.0\tTest Acc 0.9429\n",
            "16000 . Training Acc 1.0\tTest Acc 0.943\n",
            "16200 . Training Acc 1.0\tTest Acc 0.9433\n",
            "16400 . Training Acc 1.0\tTest Acc 0.9431\n",
            "16600 . Training Acc 1.0\tTest Acc 0.9431\n",
            "16800 . Training Acc 1.0\tTest Acc 0.9432\n",
            "17000 . Training Acc 1.0\tTest Acc 0.9437\n",
            "17200 . Training Acc 1.0\tTest Acc 0.9439\n",
            "17400 . Training Acc 1.0\tTest Acc 0.9439\n",
            "17600 . Training Acc 1.0\tTest Acc 0.944\n",
            "17800 . Training Acc 1.0\tTest Acc 0.9441\n",
            "18000 . Training Acc 1.0\tTest Acc 0.9439\n",
            "18200 . Training Acc 1.0\tTest Acc 0.9437\n",
            "18400 . Training Acc 1.0\tTest Acc 0.9442\n",
            "18600 . Training Acc 1.0\tTest Acc 0.9445\n",
            "18800 . Training Acc 1.0\tTest Acc 0.9445\n",
            "19000 . Training Acc 1.0\tTest Acc 0.9444\n",
            "19200 . Training Acc 1.0\tTest Acc 0.9444\n",
            "19400 . Training Acc 1.0\tTest Acc 0.9225\n",
            "19600 . Training Acc 1.0\tTest Acc 0.9293\n",
            "19800 . Training Acc 1.0\tTest Acc 0.7009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7FmDa5TtuZM"
      },
      "source": [
        "def plot_images(fake_images):\n",
        "    \n",
        "    plt.figure(figsize=(2.2, 2.2))\n",
        "    num_images = 16\n",
        "    \n",
        "    image_size = 28\n",
        "    rows = 4\n",
        "    \n",
        "    for i in range(num_images):\n",
        "        plt.subplot(rows, rows, i + 1)\n",
        "        image = np.reshape(fake_images[i], [image_size, image_size])\n",
        "        image = (image + 1)/2\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.show()   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRMuzkP1Bjle"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}