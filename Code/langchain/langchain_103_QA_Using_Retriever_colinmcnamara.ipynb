{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGA5kUcsq+0+mJdob+caro",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/colinmcnamara/austin_langchain/blob/main/QA_Using_Retriever.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install langchain openai chromadb tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKY5DCVJ19WG",
        "outputId": "dac587b5-c216-4ba2-c27e-73ce907234fc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample vars.env\n",
        "Save this as vars.env in the root of your google drive\n",
        "\n",
        "https://github.com/colinmcnamara/austin_langchain/blob/main/labs/sample.vars.env"
      ],
      "metadata": {
        "id": "f0c_6WQS2Aig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q colab_env"
      ],
      "metadata": {
        "id": "aBNVEix8j8XI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import langchain\n",
        "import openai\n",
        "import os"
      ],
      "metadata": {
        "id": "66jDgf-rXmvk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473bdb66-e411-4892-db5d-51b5e72f6dca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key=os.environ['OPENAI_API_KEY']"
      ],
      "metadata": {
        "id": "8WsfvyC1YC96"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cM1llUJu16dN"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy state_of_the_union.txt to the root of your gdrive\n",
        "https://github.com/colinmcnamara/austin_langchain/blob/main/labs/LangChain_102/state_of_the_union.txt"
      ],
      "metadata": {
        "id": "HgLAeJZm2naq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = TextLoader(\"/content/gdrive/MyDrive/state_of_the_union.txt\")\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "docsearch = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=docsearch.as_retriever())"
      ],
      "metadata": {
        "id": "0y36KcJ72UI3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "WEzbd7EY3T1e",
        "outputId": "10c0a714-86c7-47a8-f772-974034a1c22e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" The president said that Ketanji Brown Jackson is one of the nation's top legal minds, a consensus builder, and has received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#chain types\n",
        "You can easily specify different chain types to load and use in the RetrievalQA chain. For a more detailed walkthrough of these types, please see this notebook.\n",
        "\n",
        "There are two ways to load different chain types. First, you can specify the chain type argument in the from_chain_type method. This allows you to pass in the name of the chain type you want to use. For example, in the below we change the chain type to map_reduce."
      ],
      "metadata": {
        "id": "tFPwj5N33VgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"map_reduce\", retriever=docsearch.as_retriever())"
      ],
      "metadata": {
        "id": "6IKPqhkP3ZXW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "2qszoKdl3fTr",
        "outputId": "aa378790-5a27-4326-e1a3-9c2bedf0068a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" The president said that Ketanji Brown Jackson is one of the nation's top legal minds, a former top litigator in private practice, a former federal public defender, from a family of public school educators and police officers, and a consensus builder who has received support from the Fraternal Order of Police and former judges appointed by Democrats and Republicans.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above way allows you to really simply change the chain_type, but it doesn't provide a ton of flexibility over parameters to that chain type. If you want to control those parameters, you can load the chain directly (as you did in this notebook) and then pass that directly to the the RetrievalQA chain with the combine_documents_chain parameter. For example:"
      ],
      "metadata": {
        "id": "4j-mmcu73d6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "qa_chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
        "qa = RetrievalQA(combine_documents_chain=qa_chain, retriever=docsearch.as_retriever())"
      ],
      "metadata": {
        "id": "9stbMSZN4G8Y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "EzRZEven4HzY",
        "outputId": "6c0b0ccb-93a8-4fe7-8730-6aceeceb3f45"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" The president said that Ketanji Brown Jackson is one of the nation's top legal minds, a former top litigator in private practice, a former federal public defender, and from a family of public school educators and police officers. He also said that she is a consensus builder and has received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Prompts\n",
        "You can pass in custom prompts to do question answering. These prompts are the same prompts as you can pass into the base question answering chain\n",
        "\n"
      ],
      "metadata": {
        "id": "glWjbbTN4JyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Answer in Italian:\"\"\"\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")"
      ],
      "metadata": {
        "id": "Ombt3kHP4JQ3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=docsearch.as_retriever(), chain_type_kwargs=chain_type_kwargs)"
      ],
      "metadata": {
        "id": "Ts-Uhip94RR8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "wMEdgXvn4SSY",
        "outputId": "e3f854ee-b8f1-496b-cf3a-1e63ef3fd0b7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Il Presidente ha detto che Ketanji Brown Jackson è uno dei migliori legali del paese, che proviene da una famiglia di insegnanti di scuole pubbliche e agenti di polizia, ed è un costruttore di consenso. Ha ricevuto supporto da parti diverse, compresi l'ordine fraterno della polizia e giudici nominati da democratici e repubblicani.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Store Options\n",
        "note, ignore for now. This is not 102"
      ],
      "metadata": {
        "id": "CdRuot9x4W-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve more documents with higher diversity- useful if your dataset has many similar documents\n",
        "docsearch.as_retriever(search_type=\"mmr\", search_kwargs={'k': 6, 'lambda_mult': 0.25})\n",
        "\n",
        "# Fetch more documents for the MMR algorithm to consider, but only return the top 5\n",
        "docsearch.as_retriever(search_type=\"mmr\", search_kwargs={'k': 5, 'fetch_k': 50})\n",
        "\n",
        "# Only retrieve documents that have a relevance score above a certain threshold\n",
        "docsearch.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={'score_threshold': 0.8})\n",
        "\n",
        "# Only get the single most similar document from the dataset\n",
        "docsearch.as_retriever(search_kwargs={'k': 1})\n",
        "\n",
        "# Use a filter to only retrieve documents from a specific paper\n",
        "docsearch.as_retriever(search_kwargs={'filter': {'paper_title':'GPT-4 Technical Report'}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNCboISq4Vey",
        "outputId": "01e2d6d9-0dff-4494-9a0d-76e55ab82ba0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x79240eae68f0>, search_type='similarity', search_kwargs={'filter': {'paper_title': 'GPT-4 Technical Report'}})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Return Source Documents\n",
        "Additionally, we can return the source documents used to answer the question by specifying an optional parameter when constructing the chain."
      ],
      "metadata": {
        "id": "nKI2cs_e4pLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=docsearch.as_retriever(search_type=\"mmr\", search_kwargs={'fetch_k': 30}), return_source_documents=True)"
      ],
      "metadata": {
        "id": "WAS6HFJo4t5t"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "result = qa({\"query\": query})"
      ],
      "metadata": {
        "id": "LS7LMw1t4vfk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"result\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "bug-EzD44w7L",
        "outputId": "a0704b90-6672-4ef3-c6e4-8044cdbe633b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" The president said that Ketanji Brown Jackson is one of our nation's top legal minds, and that she will continue Justice Breyer's legacy of excellence.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"source_documents\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIvjVhxs4yhp",
        "outputId": "6b18fde2-5041-42b2-add7-5af3aaf78514"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \\n\\nTonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.', metadata={'source': '/content/gdrive/MyDrive/state_of_the_union.txt'}),\n",
              " Document(page_content='We can’t change how divided we’ve been. But we can change how we move forward—on COVID-19 and other issues we must face together. \\n\\nI recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \\n\\nThey were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \\n\\nOfficer Mora was 27 years old. \\n\\nOfficer Rivera was 22. \\n\\nBoth Dominican Americans who’d grown up on the same streets they later chose to patrol as police officers. \\n\\nI spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves. \\n\\nI’ve worked on these issues a long time. \\n\\nI know what works: Investing in crime preventionand community police officers who’ll walk the beat, who’ll know the neighborhood, and who can restore trust and safety.', metadata={'source': '/content/gdrive/MyDrive/state_of_the_union.txt'}),\n",
              " Document(page_content='One was stationed at bases and breathing in toxic smoke from “burn pits” that incinerated wastes of war—medical and hazard material, jet fuel, and more. \\n\\nWhen they came home, many of the world’s fittest and best trained warriors were never the same. \\n\\nHeadaches. Numbness. Dizziness. \\n\\nA cancer that would put them in a flag-draped coffin. \\n\\nI know. \\n\\nOne of those soldiers was my son Major Beau Biden. \\n\\nWe don’t know for sure if a burn pit was the cause of his brain cancer, or the diseases of so many of our troops. \\n\\nBut I’m committed to finding out everything we can. \\n\\nCommitted to military families like Danielle Robinson from Ohio. \\n\\nThe widow of Sergeant First Class Heath Robinson.  \\n\\nHe was born a soldier. Army National Guard. Combat medic in Kosovo and Iraq. \\n\\nStationed near Baghdad, just yards from burn pits the size of football fields. \\n\\nHeath’s widow Danielle is here with us tonight. They loved going to Ohio State football games. He loved building Legos with their daughter.', metadata={'source': '/content/gdrive/MyDrive/state_of_the_union.txt'}),\n",
              " Document(page_content='And I’m taking robust action to make sure the pain of our sanctions  is targeted at Russia’s economy. And I will use every tool at our disposal to protect American businesses and consumers. \\n\\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \\n\\nAmerica will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \\n\\nThese steps will help blunt gas prices here at home. And I know the news about what’s happening can seem alarming. \\n\\nBut I want you to know that we are going to be okay. \\n\\nWhen the history of this era is written Putin’s war on Ukraine will have left Russia weaker and the rest of the world stronger. \\n\\nWhile it shouldn’t have taken something so terrible for people around the world to see what’s at stake now everyone sees it clearly.', metadata={'source': '/content/gdrive/MyDrive/state_of_the_union.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}