%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{}
\begin{center}
{\Large Overview}
\end{center}
\end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Overview of Prompt Engineering}

% \begin{itemize}
  % \item \textbf{Introduction}
    % \begin{itemize}
      % \item Large Language Models (LLMs) differ from traditional ML models.
      % \item LLMs provide unique insights without requiring retraining.
    % \end{itemize}
  
  % \item \textbf{Transformational Impact}
    % \begin{itemize}
      % \item LLMs have catalyzed a transformative wave in programming.
      % \item Enables effortless computer programming through simple text prompts.
    % \end{itemize}

  % \item \textbf{Prompt Engineering Technique}
    % \begin{itemize}
      % \item Technique for directing LLM responses without altering model weights.
      % \item Relies on strategic in-context prompting.
      % \item Art of effectively communicating with AI for desired outcomes.
    % \end{itemize}
  
  % \item \textbf{Application Spectrum}
    % \begin{itemize}
      % \item Applied across various tasks: question-answering, arithmetic reasoning, etc.
      % \item Serves as a versatile tool to explore LLM boundaries and potentials.
    % \end{itemize}
% \end{itemize}

% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Background}

% Models for prediction:

% \begin{itemize}
% \item On data, derive features, put statistical techniques like regression. One model per task. That's Machine Learning.
% \item Feed raw data, employ neural networks. One model per task. That's Deep Learning.
% \item Use Text data, get embeddings, use ML/DL, say for classification. One model per task. That's Natural Language Processing.
% \item Train neural network on large corpus, store weights and architecture, then add final layers for say classification on custom data+labels. That's Pretrained model. One model, many tasks.
% \item Train Large Language Model, just supply instructions on what to do, works. One model many tasks. Zero-shot, few-shots.
% \end{itemize}

% {\tiny (More info at SaaS LLM https://medium.com/google-developer-experts/saasgpt-84ba80265d0f)}

% \end{frame}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{What is Prompt Engineering?}

Prompt engineering is a NLP concept that involves discovering inputs that yield desirable or useful results


\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{promptengg2}

{\tiny (Ref: Cohere https://docs.cohere.ai/docs/prompt-engineering)}

\end{center}				
			
			

\end{frame}



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{What is a Language Models?}

% \begin{itemize}
% \item While typing SMS, have you seen it suggests next word?
% \item While typing email, have you seen next few words are suggested?
% \item How does it suggest? (suggestions are not random, right?)
% \item In the past, for ``Lets go for a \ldots', if you have typed 'coffee' 15 times, 'movie' say 4 times, then it learns that. Machine/Statistical Learning.
% \item Next time, when you type ``Lets go for a '', what will be suggested? why?
% \item This is called Language Model. Predicting the next word. When done continuously, one after other, it spits sentence, called Generative Model.
% \end{itemize}	

% \begin{center}
% \includegraphics[width=0.6\linewidth,keepaspectratio]{chatgpt34}
% \end{center}		

% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Evolution of Language Models}

% Language Models can be statistical (frequency based) or Machine/Deep Learning (supervised) based. Simple to complex.

% \begin{center}
% \includegraphics[width=\linewidth,keepaspectratio]{chatgpt30}
% \end{center}				
% {\tiny (Ref: Analytics Vidhya https://editor.analyticsvidhya.com/uploads/59483evolution\_of\_NLP.png)}

% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Large Language Models - Comparison}

% \begin{center}
% \includegraphics[width=\linewidth,keepaspectratio]{chatgpt31}
% \end{center}				
% {\tiny (Ref: Deus.ai https://www.deus.ai/post/gpt-3-what-is-all-the-excitement-about)}

% \end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{What is Prompt Engineering?}

\begin{itemize}
\item For prompt \lstinline|What is 1,000,000 * 9,000?| GPT-3 (text-davinci-002) (sometimes) answers 9,000,000 (incorrect). This is where prompt engineering comes in.
\item If, instead of asking What is \lstinline|1,000,000 * 9,000?|, we ask \lstinline|What is 1,000,000 * 9,000? Make sure to put the right amount of zeros, even if there are many:|, GPT-3 will answer 9,000,000,000 (correct). 
\item Why is this the case? Why is the additional specification of the number of zeros necessary for the AI to get the right answer? How can we create prompts that yield optimal results on our task? 			
\item That's Prompt Engineering.
\end{itemize}

{\tiny (Ref: https://learnprompting.org/docs/basics/prompting)}
\end{frame}



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{What is Prompt Engineering?}

% How to talk to AI to get it to do what you want


% \begin{center}
% \includegraphics[width=\linewidth,keepaspectratio]{promptengg3}

% {\tiny (Ref: Human Loop https://humanloop.com/blog/prompt-engineering-101)}

% \end{center}				
			
			

% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{What is Prompt Engineering?}

% But need to tell, for sure, else, nothing


% \begin{center}
% \includegraphics[width=\linewidth,keepaspectratio]{promptengg4}

% {\tiny (Ref: Human Loop https://humanloop.com/blog/prompt-engineering-101)}

% \end{center}				

% \end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{}
\begin{center}
{\Large Sample (Simple) Gen AI Applications of Prompts}
\end{center}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Text Summarization}
\begin{itemize}
    \item Text summarization is a standard task in natural language generation.
    \item Summarizing information about antibiotics.
\end{itemize}
\begin{lstlisting}[language=HTML]
Prompt:
Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the bodys immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance.
Explain the above in one sentence:

Output:
Antibiotics are medications used to treat bacterial infections by either killing the bacteria or stopping them from reproducing, but they are not effective against viruses and overuse can lead to antibiotic resistance.
\end{lstlisting}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Information Extraction}
\begin{itemize}
    \item Language models can perform classification and other NLP tasks.
    \item Example: Extracting specific information from a paragraph.
\end{itemize}
\begin{lstlisting}[language=HTML]
Prompt:
Author-contribution statements and acknowledgements in research papers should state clearly and specifically whether, and to what extent, the authors used AI technologies such as ChatGPT in the preparation of their manuscript and analysis. They should also indicate which LLMs were used. This will alert editors and reviewers to scrutinize manuscripts more carefully for potential biases, inaccuracies and improper source crediting. Likewise, scientific journals should be transparent about their use of LLMs, for example when selecting submitted manuscripts.

Mention the large language model based product mentioned in the paragraph above:

Output:
The large language model based product mentioned in the paragraph above is ChatGPT.
\end{lstlisting}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Question Answering}
\begin{itemize}
    \item Structured prompts combine instructions, context, input, and output indicators.
    \item Example: Using context to answer a specific question. Context obtained from [Nature](https://www.nature.com/articles/d41586-023-00400-x).
\end{itemize}
\begin{lstlisting}[language=HTML]
Answer the question based on the context below. Keep the answer short. Respond "Unsure about answer" if not sure about the answer.

Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.

Question: What was OKT3 originally sourced from?

Answer:

Output:
Mice.
\end{lstlisting}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Text Classification}
\begin{itemize}
    \item Providing examples in prompts improves model specificity.
    \item Simple text classification.
\end{itemize}
\begin{lstlisting}[language=HTML]
Prompt:
Classify the text into neutral, negative or positive. 
Text: I think the food was okay. 
Sentiment:
Output:
Neutral
\end{lstlisting}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Text Classification}
Example: Using examples to enforce specific behavior.
\begin{lstlisting}[language=HTML]
Prompt:
Classify the text into neutral, negative or positive. 
Text: I think the vacation is okay.
Sentiment: neutral 

Text: I think the food was okay. 
Sentiment:
Output:
neutral
\end{lstlisting}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Conversation}
\begin{itemize}
    \item Instructing system behavior through role prompting.
    \item Example 1: Creating a technical and scientific AI research assistant.
\end{itemize}
\begin{lstlisting}[language=HTML]
Prompt:
The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.

Human: Hello, who are you?
AI: Greeting! I am an AI research assistant. How can I help you today?
Human: Can you tell me about the creation of blackholes?
AI:
Output:
Sure! Black holes are regions of spacetime where the gravitational force is so strong that nothing, not even light, can escape from it. They are created when a very massive star dies and its core collapses in on itself, forming a singularity of infinite density. The intense gravity of the singularity pulls in all the matter and radiation around it, creating the black hole.
\end{lstlisting}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Code Generation}
\begin{itemize}
    \item Language models are effective for code-generation tasks.
    \item Example 1: Generating a program to greet the user.
\end{itemize}
\begin{lstlisting}[language=HTML]
Prompt:
/*
Ask the user for their name and say "Hello"
*/
Output:
let name = prompt("What is your name?");
console.log(`Hello, ${name}!`);
\end{lstlisting}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Code Generation}
\begin{itemize}
    \item Example 2: Generating MySQL queries from a schema description.
\end{itemize}
\begin{lstlisting}[language=HTML]
Prompt:
"""
Table departments, columns = [DepartmentId, DepartmentName]
Table students, columns = [DepartmentId, StudentId, StudentName]
Create a MySQL query for all students in the Computer Science Department
"""
Output:
SELECT StudentId, StudentName 
FROM students 
WHERE DepartmentId IN (SELECT DepartmentId FROM departments WHERE DepartmentName = 'Computer Science');
\end{lstlisting}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Reasoning}
\begin{itemize}
    \item Language models require advanced techniques for reasoning tasks.
    \item Example 1: Simple arithmetic.
\end{itemize}
\begin{lstlisting}[language=HTML]
Prompt:
What is 9,000 * 9,000?
Output:
81,000,000
\end{lstlisting}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Reasoning}
\begin{itemize}
    \item Example 2: Problem-solving with step-by-step instructions.
\end{itemize}
\begin{lstlisting}[language=HTML]
Prompt:
The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. 
Solve by breaking the problem into steps. First, identify the odd numbers, add them, and indicate whether the result is odd or even. 
Output:
Odd numbers: 15, 5, 13, 7, 1
Sum: 41 
41 is an odd number.
\end{lstlisting}
\end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Text Generation}

% \begin{center}
% \includegraphics[width=\linewidth,keepaspectratio]{promptengg10}

% {\tiny (Ref: Prompt Engineering Sudalai Rajkumar)}

% \end{center}		
		


% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Text Classification}

% \begin{center}
% \includegraphics[width=\linewidth,keepaspectratio]{promptengg11}

% {\tiny (Ref: Prompt Engineering Sudalai Rajkumar)}

% \end{center}		
		


% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Text Translation}

% \begin{center}
% \includegraphics[width=\linewidth,keepaspectratio]{promptengg12}

% {\tiny (Ref: Prompt Engineering Sudalai Rajkumar)}

% \end{center}		
		


% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Text Comprehension}

% \begin{center}
% \includegraphics[width=\linewidth,keepaspectratio]{promptengg13}

% {\tiny (Ref: Prompt Engineering Sudalai Rajkumar)}

% \end{center}		
		


% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Text Summarization}
      % \begin{itemize}
          % \item Summarizes articles or concepts into concise formats.
          % \item Example: 
% \begin{lstlisting}[language=HTML]
% Prompt:
% Explain antibiotics in one sentence:
% \end{lstlisting}
          % \item Output: A clear, condensed explanation of antibiotics.
      % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Text Summarization}

% \begin{center}
% \includegraphics[width=\linewidth,keepaspectratio]{promptengg14}

% {\tiny (Ref: Prompt Engineering Sudalai Rajkumar)}

% \end{center}		
		


% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Image Generation}

\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{promptengg15}

{\tiny (Ref: Prompt Engineering Sudalai Rajkumar)}

\end{center}		
		
		
Models / Tools: Dall-E , Midjourney, Stable Diffusion



\end{frame}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{For generating code using Codex}

% Provide Codex with a prompt consisting of the following:



% \begin{itemize}
% \item  High level task description: Tell the model to use a helpful tone when outputting natural language
% \item  High level context: Describe background information like API hints and database schema to help the model understand the task
% \item  Examples: Show the model examples of what you want
% \item  User input: Remind the model what the user has said before
% \end{itemize}	 

% {\tiny (Ref: https://microsoft.github.io/prompt-engineering/)}

% \end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Programmatic Calling of Prompt}

\begin{lstlisting}[language=Python]
import openai
import os

from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv())

openai.api_key  = os.getenv('OPENAI_API_KEY') # for langchain it does it automatically

def get_completion(prompt, model="gpt-3.5-turbo"):
    messages = [{"role": "user", "content": prompt}]
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=0, # this is the degree of randomness of the model's output
    )
    return response.choices[0].message["content"]
\end{lstlisting}
		
\end{frame}

